{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44aa23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus.reader.bnc import BNCCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f92d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten, MaxPooling1D, Input, Concatenate\n",
    "from keras.models import load_model\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6440b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction = ['adventure','fiction','mystery' , 'romance', 'science_fiction']\n",
    "nonfiction = ['government','hobbies','learned','news', 'reviews'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38629f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_ids = [x for y in fiction for x in brown.fileids(categories=y)]\n",
    "nonfiction_ids = [x for y in nonfiction for x in brown.fileids(categories=y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db31ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index, fileid in enumerate(fiction_ids+nonfiction_ids):\n",
    "    paras = brown.paras(fileids=fileid)\n",
    "    label = 1 if fileid in fiction_ids else 0\n",
    "#     label = 'fiction' if fileid in fiction_ids else 'non_fiction'\n",
    "    for j, p in enumerate(paras):\n",
    "        if len(p) > 4 and len(p) < 7:\n",
    "            text = ''\n",
    "            for sent in p:\n",
    "                text = text + ' '.join(sent) + ' '\n",
    "            text = text.strip().lower()\n",
    "            temp = {}\n",
    "            temp['id'] = f'{fileid}_para_{j}'\n",
    "            temp['para'] = text\n",
    "            temp['label'] = label\n",
    "            data.append(temp)\n",
    "#     print('Finished', index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a7d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brown = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f657d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = df_brown['para'].to_list()\n",
    "y_train  = df_brown['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16e94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "emmbed_dict = {}\n",
    "with open('/home/mindbowser/MS/MS_SEM_9_Final/Brown_Corpus_Analysis/Analysis/Deep Learning model/glove.6B.100d.txt','r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:],'float32')\n",
    "        emmbed_dict[word]=vector\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0f24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb (vocab_size, words_to_index):\n",
    "    emb_matrix = np.zeros((vocab_size, 100))\n",
    "    for word, index in words_to_index.items():\n",
    "        embedding_vector =emmbed_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            emb_matrix[index, :] = embedding_vector\n",
    "    return emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0360b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "X_train = tokenizer.texts_to_sequences(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "882248e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index = tokenizer.word_index\n",
    "vocab_size = len(words_to_index) + 1  # Adding 1 because of reserved 0 index\n",
    "maxlen = max(len(x) for x in X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae134c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asfarray(pad_sequences(X_train, padding='post', maxlen=maxlen))\n",
    "y_train = np.asfarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "169f5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = emb(vocab_size, words_to_index)\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6b55c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "151/151 [==============================] - 4s 22ms/step - loss: 0.3419 - accuracy: 0.8556\n",
      "Epoch 2/3\n",
      "151/151 [==============================] - 3s 22ms/step - loss: 0.1105 - accuracy: 0.9695\n",
      "Epoch 3/3\n",
      "151/151 [==============================] - 3s 22ms/step - loss: 0.0395 - accuracy: 0.9914\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0134 - accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen, weights = [weight]))\n",
    "model.add(layers.Conv1D(100, 3, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Fit model\n",
    "history = model.fit(X_train, y_train,\n",
    "                        epochs=3,\n",
    "                        verbose=True,\n",
    "                        batch_size=10,)\n",
    "#                         validation_data=(X_test, y_test))\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9ae7954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9993\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy:  {:.4f}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04a1eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=True)\n",
    "# test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba86e0",
   "metadata": {},
   "source": [
    "# Baby BNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc7ecf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fict_ids = os.listdir(r\"../../baby_bnc_corpus/Texts/fic/\")\n",
    "non_fict_ids = os.listdir(r\"../../baby_bnc_corpus/Texts/aca/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ed2650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_data = []\n",
    "for i, xmlfile in enumerate(fict_ids):\n",
    "    tree = ET.parse(f\"../../baby_bnc_corpus/Texts/fic/{xmlfile}\")\n",
    "    root = tree.getroot()\n",
    "    paras = root.findall('.wtext/div/p')\n",
    "    for j, p in enumerate(paras):\n",
    "        sents = p.findall('s')\n",
    "        if len(sents) > 4 and len(sents) < 7:\n",
    "            sen_list = []\n",
    "            for s in p.findall('s'):\n",
    "                sen = ''.join([w.text.lower() for w in s if w.text]).strip()\n",
    "                sen_list.append(sen)\n",
    "            texts = ' '.join(sen_list)\n",
    "            temp = {}\n",
    "            temp['para'] = texts\n",
    "            temp['id'] = f'{xmlfile}_para_{j}'\n",
    "            temp['label'] = 1\n",
    "            fic_data.append(temp)\n",
    "#     print('Finished', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41601ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fic_data = []\n",
    "for i, xmlfile in enumerate(non_fict_ids):\n",
    "    tree = ET.parse(f\"../../baby_bnc_corpus/Texts/aca/{xmlfile}\")\n",
    "    root = tree.getroot()\n",
    "    paras = root.findall('.wtext/div/p')\n",
    "    for j, p in enumerate(paras):\n",
    "        sents = p.findall('s')\n",
    "        if len(sents) > 4 and len(sents) < 7:\n",
    "            sen_list = []\n",
    "            for s in p.findall('s'):\n",
    "                sen = ''.join([w.text.lower() for w in s if w.text]).strip()\n",
    "                sen_list.append(sen)\n",
    "            temp = {}\n",
    "            temp['id'] = f'{xmlfile}_para_{j}'\n",
    "            temp['para'] = ' '.join(sen_list)\n",
    "            temp['label'] = 0\n",
    "            non_fic_data.append(temp)\n",
    "#     print('Finished', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b37a2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fic_data + non_fic_data\n",
    "df_baby = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c63e10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_fict = df_baby[df_baby.label == 0].reset_index()\n",
    "df_non_fict.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b21f5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for i in range(10):\n",
    "    df_fict = df_baby[df_baby.label == 1].sample(250, random_state=i).reset_index()\n",
    "    df_fict.drop(['index'], axis=1, inplace=True)\n",
    "    df_final = df_fict.append(df_non_fict, ignore_index=True)\n",
    "    dfs[i] = df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87aece4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predictions = {}\n",
    "scores = []\n",
    "reports = []\n",
    "for i, test in dfs.items():\n",
    "    #test text and labels\n",
    "    text_test = test['para'].to_list()\n",
    "    y_test  = test['label'].to_list()\n",
    "    X_test = tokenizer.texts_to_sequences(text_test)\n",
    "    \n",
    "    X_test = np.asfarray(pad_sequences(X_test, padding='post', maxlen=maxlen))\n",
    "    y_test = np.asfarray(y_test)\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "    scores.append(test_accuracy)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    X_pred = np.asfarray([1 if x>0.5 else 0 for x in pred])\n",
    "    report = classification_report(y_test, X_pred, output_dict=True)\n",
    "    reports.append(report)\n",
    "    \n",
    "    X_predictions[i] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bb0eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96.93711996078491, 0.41021850939284377)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores) *100 , np.std(scores) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4a896c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9689696564277064, 0.0042891988044478566)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([x['1.0']['f1-score'] for x in reports]), np.std([x['1.0']['f1-score'] for x in reports])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bee6296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9697614409026892, 0.003923716746956489)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([x['0.0']['f1-score'] for x in reports]), np.std([x['0.0']['f1-score'] for x in reports])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a06374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9695740342140198,\n",
       " 0.9675456285476685,\n",
       " 0.9655172228813171,\n",
       " 0.9716024398803711,\n",
       " 0.9736308455467224,\n",
       " 0.9716024398803711,\n",
       " 0.9716024398803711,\n",
       " 0.9614604711532593,\n",
       " 0.9756592512130737,\n",
       " 0.9655172228813171]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba12a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf4598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea65b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b8fcfca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd90075a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa616f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1261d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859c756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
