{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import stanza\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-genres\n",
    "fiction = ['adventure','fiction','mystery' , 'romance', 'science_fiction']\n",
    "nonfiction = ['government','hobbies','learned','news', 'reviews'] \n",
    "\n",
    "# fileids\n",
    "fiction_ids = [x for y in fiction for x in brown.fileids(categories=y)]\n",
    "nonfiction_ids = [x for y in nonfiction for x in brown.fileids(categories=y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _lex_den(temp):\n",
    "#     feat = Features(nlp_pipeline=nlp, text=temp['text'])\n",
    "#     pos_counts_output = feat._pos_counts()\n",
    "#     pos_counts_output['id'] = temp['id']\n",
    "#     pos_counts_output['label'] = temp['label']\n",
    "#     return pos_counts_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [00:01, 253.11it/s]\n"
     ]
    }
   ],
   "source": [
    "lex_den_data = []\n",
    "for index, fileid in tqdm(enumerate(fiction_ids+nonfiction_ids)):\n",
    "    paras = brown.paras(fileids=fileid)\n",
    "    \n",
    "    label = 1 if fileid in fiction_ids else 0\n",
    "\n",
    "    for j, p in enumerate(paras):\n",
    "        if len(p) > 4 and len(p) < 7:\n",
    "            text = ' '\n",
    "            for sent in p: \n",
    "                text = text + ' '.join(sent)+' '\n",
    "            text = text.strip()\n",
    "            # pos_counts = _lex_den(text)\n",
    "            temp = {}\n",
    "            temp['id'] =f'{fileid}_para_{j}'\n",
    "            temp['label'] = label\n",
    "            temp['text'] = text\n",
    "            lex_den_data.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Parellilizing the computation\n",
    "# start_time = time.perf_counter()\n",
    "# lex_den_outputs = Parallel(n_jobs=4, prefer=\"threads\")(delayed(_lex_den)(dic) for dic in lex_den_data)\n",
    "# finish_time = time.perf_counter()\n",
    "# print(f\"Finished in {finish_time-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When , in late afternoon on the last day in June , he saw two people top the ridge to the south and walk toward the house , he quit work immediately and strode to his rifle . It could be some kind of trick Budd had thought up . No one walked in this country , least of all Ed Dow or Dutch Renfro or any of the rest of the Bar B crew . Morgan watched the two figures for a time , puzzled . When they were closer and he saw that one was a woman , he was more puzzled than ever .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = lex_den_data[0]['text']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 15:35:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 4.71MB/s]                    \n",
      "2023-11-14 15:35:08 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | spacy               |\n",
      "| pos          | combined_charlm     |\n",
      "| lemma        | combined_nocharlm   |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "| depparse     | combined_charlm     |\n",
      "| sentiment    | sstplus             |\n",
      "| ner          | ontonotes_charlm    |\n",
      "======================================\n",
      "\n",
      "2023-11-14 15:35:08 INFO: Using device: cpu\n",
      "2023-11-14 15:35:08 INFO: Loading: tokenize\n",
      "2023-11-14 15:35:08 INFO: Loading: pos\n",
      "2023-11-14 15:35:08 INFO: Loading: lemma\n",
      "2023-11-14 15:35:08 INFO: Loading: constituency\n",
      "2023-11-14 15:35:09 INFO: Loading: depparse\n",
      "2023-11-14 15:35:09 INFO: Loading: sentiment\n",
      "2023-11-14 15:35:10 INFO: Loading: ner\n",
      "2023-11-14 15:35:10 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from src.extract_all_features import Features\n",
    "nlp = stanza.Pipeline(lang='en', processors={'tokenize': 'spacy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = Features(nlp_pipeline=nlp, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_sen_len': 21.4, 'std_sen_len': 9.951884243699782}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat._extract_features(choice='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "sents = []\n",
    "for sent in doc.sentences:\n",
    "    sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When , in late afternoon on the last day in June , he saw two people top the ridge to the south and walk toward the house , he quit work immediately and strode to his rifle .',\n",
       " 'It could be some kind of trick Budd had thought up .',\n",
       " 'No one walked in this country , least of all Ed Dow or Dutch Renfro or any of the rest of the Bar B crew .',\n",
       " 'Morgan watched the two figures for a time , puzzled .',\n",
       " 'When they were closer and he saw that one was a woman , he was more puzzled than ever .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join([w.text for w in s.words]).strip()  for s in doc.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
